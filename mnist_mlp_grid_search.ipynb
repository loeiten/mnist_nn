{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we train an MLP to classify images from the MNIST database.\n",
    "\n",
    "### 1. Load MNIST Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "# use Keras to import pre-shuffled MNIST database\n",
    "# NOTE: Hold out one test set for final evaluation\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Rescale the Images by Dividing Every Pixel in Every Image by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale [0,255] --> [0,1]\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Encode Categorical Integer Labels Using a One-Hot Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_ohe_train = np_utils.to_categorical(y_ohe_train, 10)\n",
    "y_ohe_test = np_utils.to_categorical(y_ohe_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define the Model Architecture Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "shape = x.shape[1:]\n",
    "# From the tuorial https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "def create_model(dropout_rate, hidden_layer, nodes, optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=shape))\n",
    "    \n",
    "    for _ in range(hidden_layer):\n",
    "        model.add(Dense(nodes, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define the Grid Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def nn_search(data_dict,\n",
    "              batch_size=[128],\n",
    "              dropout_rate=[0.2],\n",
    "              epochs=[10],\n",
    "              hidden_layers=[2],\n",
    "              nodes=[512],\n",
    "              optimizer=['rmsprop']):\n",
    "    \n",
    "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "    param_grid = dict(batch_size=batch_size,\n",
    "                      dropout_rate=dropout_rate,\n",
    "                      epochs=epochs,\n",
    "                      nodes=nodes,\n",
    "                      optimizer=optimizer)\n",
    "    \n",
    "    # NOTE: 3-fold cross validation is the default\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "    grid_result = grid.fit(x_train, y_ohe_train)\n",
    "\n",
    "    data_dict[grid_result.cv_results_['params']] = grid_result.cv_results_['mean_test_score']\n",
    "    \n",
    "    # summarize results\n",
    "    print(\"Best: {} using {}\".format(grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"{} ({}) with: {}\".format(mean, stdev, param))\n",
    "        \n",
    "    return data_dict    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Run Using the Different Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We do not do a full grid-search as that is too time consuming\n",
    "#       Instead we would like to investigate how the score changes with the parameters\n",
    "\n",
    "data_dict = dict()\n",
    "\n",
    "# Run with standard parameters\n",
    "data_dict = nn_search(data_dict)\n",
    "\n",
    "batch_size = [64, 256]\n",
    "for bs in batch_size:\n",
    "    data_dict = nn_search(data_dict, batch_size=bs)\n",
    "    \n",
    "dropout_rate = [0.1, 0.4]\n",
    "for dr in dropout_rate:\n",
    "    data_dict = nn_search(data_dict, dropout_rate=dr)\n",
    "\n",
    "epochs = [5, 20]\n",
    "for e in epochs:\n",
    "    data_dict = nn_search(data_dict, epochs=e)\n",
    "\n",
    "hidden_layers = [1, 3]\n",
    "for hl in hidden_layers:\n",
    "    data_dict = nn_search(data_dict, hidden_layers=hl)\n",
    "\n",
    "nodes = [256, 1024]\n",
    "for n in nodes:\n",
    "    data_dict = nn_search(data_dict, nodes=n)\n",
    "\n",
    "optimizer = ['sdg', 'adadelta']    \n",
    "for o in optimizer:\n",
    "    data_dict = nn_search(data_dict, optimizer=o)\n",
    "    \n",
    "# TODO: Plot trends\n",
    "# TODO: Take the best of all worlds, and check evaluate against the final test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Calculate the Classification Accuracy on the Test Set (Before Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_split=0.2, callbacks=[checkpointer],\n",
    "          verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Load the Model with the Best Classification Accuracy on the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('mnist.model.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Calculate the Classification Accuracy on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate test accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
